main.py:173: UserWarning: If you have Pandas 1.0 you must make the following change manually for cox to work: https://github.com/MadryLab/cox/pull/3/files
  "If you have Pandas 1.0 you must make the following change manually for cox to work: https://github.com/MadryLab/cox/pull/3/files")
Logging in: /gpfs/loomis/home.grace/sls248/transductions/logs/default/negation-results-6-28-20_0/1ccf0ca0-ff88-4037-a590-949ee7955e30
Training epoch 1/100 on train data
Evaluating epoch 1/100 on val data
sentence-level-accuracy   0.188 %
token-level-accuracy      24.201 %
that-which-accuracy       18.105 %
because-since-accuracy    0.66254 %
can-may-must-should-accuracy 40.956 %
not-accuracy              63.178 %
loss                      2.7632 
Training epoch 2/100 on train data
Evaluating epoch 2/100 on val data
sentence-level-accuracy   7.368 %
token-level-accuracy      49.379 %
that-which-accuracy       72.268 %
because-since-accuracy    31.257 %
can-may-must-should-accuracy 62.539 %
not-accuracy              82.476 %
loss                      1.6879 
Training epoch 3/100 on train data
Evaluating epoch 3/100 on val data
sentence-level-accuracy   42.748 %
token-level-accuracy      65.979 %
that-which-accuracy       74.89 %
because-since-accuracy    45.086 %
can-may-must-should-accuracy 70.763 %
not-accuracy              87.077 %
loss                      1.0243 
Training epoch 4/100 on train data
Evaluating epoch 4/100 on val data
sentence-level-accuracy   59.755 %
token-level-accuracy      76.107 %
that-which-accuracy       79.54 %
because-since-accuracy    65.185 %
can-may-must-should-accuracy 78.949 %
not-accuracy              90.992 %
loss                      0.61589 
Training epoch 5/100 on train data
Evaluating epoch 5/100 on val data
sentence-level-accuracy   68.38 %
token-level-accuracy      81.051 %
that-which-accuracy       84.023 %
because-since-accuracy    73.706 %
can-may-must-should-accuracy 81.966 %
not-accuracy              93.28 %
loss                      0.43302 
Training epoch 6/100 on train data
Evaluating epoch 6/100 on val data
sentence-level-accuracy   72.228 %
token-level-accuracy      83.462 %
that-which-accuracy       85.222 %
because-since-accuracy    80.784 %
can-may-must-should-accuracy 84.937 %
not-accuracy              94.41 %
loss                      0.34355 
Training epoch 7/100 on train data
Evaluating epoch 7/100 on val data
sentence-level-accuracy   74.735 %
token-level-accuracy      85.785 %
that-which-accuracy       87.152 %
because-since-accuracy    83.303 %
can-may-must-should-accuracy 86.631 %
not-accuracy              95.115 %
loss                      0.28982 
Training epoch 8/100 on train data
Evaluating epoch 8/100 on val data
sentence-level-accuracy   76.438 %
token-level-accuracy      87.08 %
that-which-accuracy       88.396 %
because-since-accuracy    85.025 %
can-may-must-should-accuracy 88.694 %
not-accuracy              95.725 %
loss                      0.25364 
Training epoch 9/100 on train data
Evaluating epoch 9/100 on val data
sentence-level-accuracy   78.27 %
token-level-accuracy      88.754 %
that-which-accuracy       89.635 %
because-since-accuracy    86.959 %
can-may-must-should-accuracy 90.561 %
not-accuracy              96.546 %
loss                      0.21793 
Training epoch 10/100 on train data
Evaluating epoch 10/100 on val data
sentence-level-accuracy   80.12 %
token-level-accuracy      90.155 %
that-which-accuracy       91.189 %
because-since-accuracy    88.683 %
can-may-must-should-accuracy 92.409 %
not-accuracy              97.12 %
loss                      0.19319 
Training epoch 11/100 on train data
Evaluating epoch 11/100 on val data
sentence-level-accuracy   81.818 %
token-level-accuracy      91.509 %
that-which-accuracy       92.473 %
because-since-accuracy    89.965 %
can-may-must-should-accuracy 93.73 %
not-accuracy              97.638 %
loss                      0.16381 
Training epoch 12/100 on train data
Evaluating epoch 12/100 on val data
sentence-level-accuracy   83.949 %
token-level-accuracy      92.66 %
that-which-accuracy       92.859 %
because-since-accuracy    92.024 %
can-may-must-should-accuracy 94.911 %
not-accuracy              97.835 %
loss                      0.14259 
Training epoch 13/100 on train data
Evaluating epoch 13/100 on val data
sentence-level-accuracy   85.059 %
token-level-accuracy      93.378 %
that-which-accuracy       93.84 %
because-since-accuracy    92.316 %
can-may-must-should-accuracy 95.401 %
not-accuracy              98.193 %
loss                      0.12742 
Training epoch 14/100 on train data
Evaluating epoch 14/100 on val data
sentence-level-accuracy   86.127 %
token-level-accuracy      93.925 %
that-which-accuracy       94.121 %
because-since-accuracy    93.459 %
can-may-must-should-accuracy 95.851 %
not-accuracy              98.391 %
loss                      0.11474 
Training epoch 15/100 on train data
Evaluating epoch 15/100 on val data
sentence-level-accuracy   86.936 %
token-level-accuracy      94.407 %
that-which-accuracy       95.041 %
because-since-accuracy    93.06 %
can-may-must-should-accuracy 96.308 %
not-accuracy              98.507 %
loss                      0.10618 
Training epoch 16/100 on train data
Evaluating epoch 16/100 on val data
sentence-level-accuracy   88.359 %
token-level-accuracy      95.082 %
that-which-accuracy       95.872 %
because-since-accuracy    94.301 %
can-may-must-should-accuracy 96.647 %
not-accuracy              98.649 %
loss                      0.095808 
Training epoch 17/100 on train data
Evaluating epoch 17/100 on val data
sentence-level-accuracy   89.981 %
token-level-accuracy      95.851 %
that-which-accuracy       96.617 %
because-since-accuracy    94.789 %
can-may-must-should-accuracy 97.233 %
not-accuracy              98.725 %
loss                      0.082956 
Training epoch 18/100 on train data
Evaluating epoch 18/100 on val data
sentence-level-accuracy   90.543 %
token-level-accuracy      96.085 %
that-which-accuracy       96.754 %
because-since-accuracy    94.802 %
can-may-must-should-accuracy 97.511 %
not-accuracy              98.885 %
loss                      0.078878 
EarlyStopping counter: 1 out of 3
Training epoch 19/100 on train data
Evaluating epoch 19/100 on val data
sentence-level-accuracy   90.06 %
token-level-accuracy      95.583 %
that-which-accuracy       96.314 %
because-since-accuracy    94.083 %
can-may-must-should-accuracy 96.589 %
not-accuracy              98.387 %
loss                      0.085549 
EarlyStopping counter: 2 out of 3
Training epoch 20/100 on train data
Evaluating epoch 20/100 on val data
sentence-level-accuracy   91.243 %
token-level-accuracy      96.428 %
that-which-accuracy       97.349 %
because-since-accuracy    95.411 %
can-may-must-should-accuracy 97.715 %
not-accuracy              99.005 %
loss                      0.071264 
Training epoch 21/100 on train data
Evaluating epoch 21/100 on val data
sentence-level-accuracy   92.28 %
token-level-accuracy      96.93 %
that-which-accuracy       97.942 %
because-since-accuracy    95.912 %
can-may-must-should-accuracy 97.733 %
not-accuracy              99.091 %
loss                      0.06233 
Training epoch 22/100 on train data
Evaluating epoch 22/100 on val data
sentence-level-accuracy   92.613 %
token-level-accuracy      97.119 %
that-which-accuracy       98.227 %
because-since-accuracy    96.15 %
can-may-must-should-accuracy 97.962 %
not-accuracy              99.157 %
loss                      0.057484 
EarlyStopping counter: 1 out of 3
Training epoch 23/100 on train data
Evaluating epoch 23/100 on val data
sentence-level-accuracy   92.71 %
token-level-accuracy      97.084 %
that-which-accuracy       97.766 %
because-since-accuracy    96.081 %
can-may-must-should-accuracy 97.935 %
not-accuracy              99.065 %
loss                      0.057638 
EarlyStopping counter: 2 out of 3
Training epoch 24/100 on train data
Evaluating epoch 24/100 on val data
sentence-level-accuracy   93.379 %
token-level-accuracy      97.46 %
that-which-accuracy       98.229 %
because-since-accuracy    96.355 %
can-may-must-should-accuracy 98.048 %
not-accuracy              99.246 %
loss                      0.051788 
Training epoch 25/100 on train data
Evaluating epoch 25/100 on val data
sentence-level-accuracy   93.229 %
token-level-accuracy      97.204 %
that-which-accuracy       98.157 %
because-since-accuracy    96.155 %
can-may-must-should-accuracy 98.101 %
not-accuracy              98.895 %
loss                      0.05516 
EarlyStopping counter: 1 out of 3
Training epoch 26/100 on train data
Evaluating epoch 26/100 on val data
sentence-level-accuracy   91.601 %
token-level-accuracy      96.403 %
that-which-accuracy       97.789 %
because-since-accuracy    95.135 %
can-may-must-should-accuracy 95.041 %
not-accuracy              98.815 %
loss                      0.065833 
EarlyStopping counter: 2 out of 3
Training epoch 27/100 on train data
Evaluating epoch 27/100 on val data
sentence-level-accuracy   94.742 %
token-level-accuracy      98.076 %
that-which-accuracy       98.868 %
because-since-accuracy    97.196 %
can-may-must-should-accuracy 98.846 %
not-accuracy              99.38 %
loss                      0.04056 
Training epoch 28/100 on train data
Evaluating epoch 28/100 on val data
sentence-level-accuracy   94.894 %
token-level-accuracy      98.101 %
that-which-accuracy       98.713 %
because-since-accuracy    97.094 %
can-may-must-should-accuracy 98.773 %
not-accuracy              99.374 %
loss                      0.039864 
EarlyStopping counter: 1 out of 3
Training epoch 29/100 on train data
Evaluating epoch 29/100 on val data
sentence-level-accuracy   94.702 %
token-level-accuracy      98.043 %
that-which-accuracy       98.822 %
because-since-accuracy    97.409 %
can-may-must-should-accuracy 98.591 %
not-accuracy              99.386 %
loss                      0.039073 
EarlyStopping counter: 2 out of 3
Training epoch 30/100 on train data
Evaluating epoch 30/100 on val data
sentence-level-accuracy   94.787 %
token-level-accuracy      97.972 %
that-which-accuracy       98.634 % (Relative Phrases)
because-since-accuracy    96.626 % (Adverb Phrases)
can-may-must-should-accuracy 98.556 % (Modal Verbs)
not-accuracy              99.344 % (Negation)
loss                      0.040604 
EarlyStopping counter: 3 out of 3
Early stopping. Loading model from last saved checkoint.
Testing on test data
Closing remaining open files:logs/default/negation-results-6-28-20_0/1ccf0ca0-ff88-4037-a590-949ee7955e30/store.h5...done


TARGET: because hagrid must prepare the baklava that snape should assemble since neville can wiggle fred can not hiccup,
PREDICTION: because hagrid must prepare the baklava that fred should assemble neville can not wiggle since snape can hiccup

TARGET: because the witch can wiggle because petunia may hide a cake james must not swim because james should wiggle,
PREDICTION: because the witch can wiggle petunia may not hide a doughnut because james must laugh because hermione should wiggle

TARGET: since draco may sprinkle the baklava since a witch should assemble the eclaire which petunia must arrange dobby should not laugh	
PREDICTION: since draco may sprinkle the baklava since a witch should assemble the eclaire dobby must not arrange the eclaires

